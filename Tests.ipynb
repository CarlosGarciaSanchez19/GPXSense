{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-09 13:29:58.192635: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-09 13:29:58.202921: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-09 13:29:58.305107: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-09 13:29:58.392773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739104198.480256    7234 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739104198.501908    7234 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-09 13:29:58.703164: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gpxSense as gpx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(y_true, y_pred, clip_delta=1.0):\n",
    "\terror = y_true - y_pred\n",
    "\tcond  = tf.keras.backend.abs(error) < clip_delta\n",
    "\n",
    "\tsquared_loss = 0.5 * tf.keras.backend.square(error)\n",
    "\tlinear_loss  = clip_delta * (tf.keras.backend.abs(error) - 0.5 * clip_delta)\n",
    "\n",
    "\treturn tf.where(cond, squared_loss, linear_loss)\n",
    "\n",
    "def huber_loss_mean(y_true, y_pred, clip_delta=1.0):\n",
    "\treturn tf.keras.backend.mean(huber_loss(y_true, y_pred, clip_delta))\n",
    "\n",
    "def combined_loss(alpha):\n",
    "    def loss(y_true, y_pred):\n",
    "        mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "        mae = tf.keras.backend.mean(tf.keras.backend.abs(y_true - y_pred))\n",
    "        return alpha * mse + (1 - alpha) * mae\n",
    "    return loss\n",
    "\n",
    "def from_df_to_tfds(df, y, shuffle=True, batch_size=32):\n",
    "\tds = tf.data.Dataset.from_tensor_slices((df.values, y.values))\n",
    "\tif shuffle:\n",
    "\t\tds = ds.shuffle(buffer_size=len(df))\n",
    "\tds = ds.batch(batch_size)\n",
    "\treturn ds\n",
    "\n",
    "def performance(model, df_train, df_norm_test, y_test):\n",
    "\tevaluations = model.evaluate(from_df_to_tfds(df_norm_test, y_test, shuffle=False, batch_size=1))\n",
    "\tmean_pred = model.predict(from_df_to_tfds(df_norm_test, y_test, shuffle=False, batch_size=1)).mean() * (df_train.max()['hr'] - df_train.min()['hr']) + df_train.min()['hr']\n",
    "\treal_mean = y_test.mean() * (df_train.max()['hr'] - df_train.min()['hr']) + df_train.min()['hr']\n",
    "\tprint(\"Mean prediction:\\n\", f\"{mean_pred:.2f} bpm\")\n",
    "\tprint(\"Real mean:\\n\", f\"{real_mean:.2f} bpm\")\n",
    "\tprint(f\"Error in the prediction:\\n\" f\"{abs(mean_pred - real_mean) / real_mean * 100 : .2f}\" + f\"%\")\n",
    "\tprint(\"Metrics:\\n\", evaluations)\n",
    "\tloss = (evaluations[0] * (df_train['hr'].max() - df_train['hr'].min()))\n",
    "\tmae_loss = (evaluations[1] * (df_train['hr'].max() - df_train['hr'].min()))\n",
    "\tprint(\"Loss:\\n\", f\"{loss:.2f} bpm\")\n",
    "\tprint(\"MAE loss:\\n\", f\"{mae_loss:.2f} bpm\")\n",
    "\tprint(f\"Error in the prediction:\\n\" f\"{(evaluations[1]) * 100 : .2f}\" + f\"%\")\n",
    "\treturn evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ele           38.432323\n",
      "hr           153.724518\n",
      "cad          178.290960\n",
      "dist        4099.041451\n",
      "time_acc      25.962660\n",
      "pace           6.197837\n",
      "dtype: float64\n",
      "6073\n"
     ]
    }
   ],
   "source": [
    "df1 = gpx.gpxAnalyseClass(\"Data/31-05-2024.gpx\").df\n",
    "df2 = gpx.gpxAnalyseClass(\"Data/05-06-2024.gpx\").df\n",
    "df3 = gpx.gpxAnalyseClass(\"Data/18-06-2024.gpx\").df\n",
    "df4 = gpx.gpxAnalyseClass(\"Data/11-07-2024.gpx\").df\n",
    "df5 = gpx.gpxAnalyseClass(\"Data/07-12-2024.gpx\").df\n",
    "df6 = gpx.gpxAnalyseClass(\"Data/09-01-2025.gpx\").df\n",
    "df7 = gpx.gpxAnalyseClass(\"Data/23-01-2025.gpx\").df\n",
    "df8 = gpx.gpxAnalyseClass(\"Data/29-01-2025.gpx\").df\n",
    "df9 = gpx.gpxAnalyseClass(\"Data/31-01-2025.gpx\").df\n",
    "df10 = gpx.gpxAnalyseClass(\"Data/04-02-2025.gpx\").df\n",
    "df11 = gpx.gpxAnalyseClass(\"Data/07-02-2025.gpx\").df\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df11], axis=0)\n",
    "df = df.drop(['lat', 'lon'], axis=1)\n",
    "df = df.select_dtypes(include=['number'])\n",
    "print(df.mean())\n",
    "print(len(df))\n",
    "df_norm = (df - df.min()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775us/step - loss: 0.0038 - mae: 0.0596\n",
      "\u001b[1m440/440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step\n",
      "Mean prediction:\n",
      " 151.45 bpm\n",
      "Real mean:\n",
      " 152.44 bpm\n",
      "Error in the prediction:\n",
      " 0.65%\n",
      "Metrics:\n",
      " [0.0035008627455681562, 0.060681745409965515]\n",
      "Loss:\n",
      " 0.41 bpm\n",
      "MAE loss:\n",
      " 7.16 bpm\n",
      "Error in the prediction:\n",
      " 6.07%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0035008627455681562, 0.060681745409965515]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpxTest = gpx.LinearPredictor(\"Data/TestingData1.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNmodelPruebas.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "performance(DNNmodel, df, df_norm_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - loss: 0.0036 - mae: 0.0587\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "Mean prediction:\n",
      " 154.17 bpm\n",
      "Real mean:\n",
      " 149.11 bpm\n",
      "Error in the prediction:\n",
      " 3.40%\n",
      "Metrics:\n",
      " [0.00473410077393055, 0.06913475692272186]\n",
      "Loss:\n",
      " 0.56 bpm\n",
      "MAE loss:\n",
      " 8.16 bpm\n",
      "Error in the prediction:\n",
      " 6.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00473410077393055, 0.06913475692272186]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpxTest = gpx.LinearPredictor(\"Data/TestingData2.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNmodelPruebas.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "performance(DNNmodel, df, df_norm_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Test 1--------\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0036 - mae: 0.0578\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step\n",
      "Mean prediction:\n",
      " 153.07 bpm\n",
      "Real mean:\n",
      " 149.11 bpm\n",
      "Error in the prediction:\n",
      " 2.65%\n",
      "Metrics:\n",
      " [0.004703052807599306, 0.0649682879447937]\n",
      "Loss:\n",
      " 0.55 bpm\n",
      "MAE loss:\n",
      " 7.67 bpm\n",
      "Error in the prediction:\n",
      " 6.50%\n",
      "--------Test 2--------\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0075 - mae: 0.1032\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step\n",
      "Mean prediction:\n",
      " 152.57 bpm\n",
      "Real mean:\n",
      " 143.21 bpm\n",
      "Error in the prediction:\n",
      " 6.54%\n",
      "Metrics:\n",
      " [0.007271388079971075, 0.0953764021396637]\n",
      "Loss:\n",
      " 0.86 bpm\n",
      "MAE loss:\n",
      " 11.25 bpm\n",
      "Error in the prediction:\n",
      " 9.54%\n",
      "--------Test 3--------\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0049 - mae: 0.0805\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Mean prediction:\n",
      " 160.91 bpm\n",
      "Real mean:\n",
      " 160.21 bpm\n",
      "Error in the prediction:\n",
      " 0.44%\n",
      "Metrics:\n",
      " [0.004223781172186136, 0.07143956422805786]\n",
      "Loss:\n",
      " 0.50 bpm\n",
      "MAE loss:\n",
      " 8.43 bpm\n",
      "Error in the prediction:\n",
      " 7.14%\n",
      "--------Test 4--------\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0126 - mae: 0.1068\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step\n",
      "Mean prediction:\n",
      " 161.44 bpm\n",
      "Real mean:\n",
      " 143.94 bpm\n",
      "Error in the prediction:\n",
      " 12.16%\n",
      "Metrics:\n",
      " [0.027571648359298706, 0.17438079416751862]\n",
      "Loss:\n",
      " 3.25 bpm\n",
      "MAE loss:\n",
      " 20.58 bpm\n",
      "Error in the prediction:\n",
      " 17.44%\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Test 1--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/08-03-2024_Test1.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNHBRMEANBS32LN00065LR.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 2--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/25-04-2024_Test2.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNHBRMEANBS32LN00065LR.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 3--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/25-01-2024_Test3.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNHBRMEANBS32LN00065LR.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 4--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/03-02-2024_Test4.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('DNNHBRMEANBS32LN00065LR.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Test 1--------\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038 - mae: 0.0534\n",
      "\u001b[1m530/530\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step\n",
      "Mean prediction:\n",
      " 152.44 bpm\n",
      "Real mean:\n",
      " 149.11 bpm\n",
      "Error in the prediction:\n",
      " 2.24%\n",
      "Metrics:\n",
      " [0.004673334304243326, 0.06025400385260582]\n",
      "Loss:\n",
      " 0.55 bpm\n",
      "MAE loss:\n",
      " 7.11 bpm\n",
      "Error in the prediction:\n",
      " 6.03%\n",
      "--------Test 2--------\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0082 - mae: 0.1022\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step\n",
      "Mean prediction:\n",
      " 152.43 bpm\n",
      "Real mean:\n",
      " 143.21 bpm\n",
      "Error in the prediction:\n",
      " 6.44%\n",
      "Metrics:\n",
      " [0.007953757420182228, 0.09495022892951965]\n",
      "Loss:\n",
      " 0.94 bpm\n",
      "MAE loss:\n",
      " 11.20 bpm\n",
      "Error in the prediction:\n",
      " 9.50%\n",
      "--------Test 3--------\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0054 - mae: 0.0781\n",
      "\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step\n",
      "Mean prediction:\n",
      " 159.86 bpm\n",
      "Real mean:\n",
      " 160.21 bpm\n",
      "Error in the prediction:\n",
      " 0.22%\n",
      "Metrics:\n",
      " [0.004314905032515526, 0.0626075491309166]\n",
      "Loss:\n",
      " 0.51 bpm\n",
      "MAE loss:\n",
      " 7.39 bpm\n",
      "Error in the prediction:\n",
      " 6.26%\n",
      "--------Test 4--------\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0128 - mae: 0.1073\n",
      "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Mean prediction:\n",
      " 160.35 bpm\n",
      "Real mean:\n",
      " 143.94 bpm\n",
      "Error in the prediction:\n",
      " 11.40%\n",
      "Metrics:\n",
      " [0.025669679045677185, 0.16644367575645447]\n",
      "Loss:\n",
      " 3.03 bpm\n",
      "MAE loss:\n",
      " 19.64 bpm\n",
      "Error in the prediction:\n",
      " 16.64%\n"
     ]
    }
   ],
   "source": [
    "print(\"--------Test 1--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/08-03-2024_Test1.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('best_model_1.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 2--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/25-04-2024_Test2.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('best_model_1.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 3--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/25-01-2024_Test3.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('best_model_1.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)\n",
    "\n",
    "print(\"--------Test 4--------\")\n",
    "gpxTest = gpx.LinearPredictor(\"Data/03-02-2024_Test4.gpx\")\n",
    "df_test = gpxTest.df\n",
    "df_norm_test = df_test.drop(['lat', 'lon'], axis=1)\n",
    "df_norm_test = df_norm_test.select_dtypes(include=['number'])\n",
    "df_norm_test = (df_norm_test - df.min()) / (df.max() - df.min())\n",
    "y_test = df_norm_test.pop('hr')\n",
    "DNNmodel = tf.keras.models.load_model('best_model_1.keras', custom_objects={'huber_loss_mean': huber_loss_mean})\n",
    "eval = performance(DNNmodel, df, df_norm_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
